{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVMKKLzGPcXj",
        "outputId": "1239fabf-984f-4747-b341-f5b6bb6cf637"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CNN**"
      ],
      "metadata": {
        "id": "ehJ8s9Yofeze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_excel('/content/drive/MyDrive/idp_dataset/pubmed_abstracts_clinicaltextrouge.xlsx')\n",
        "\n",
        "# Preprocessing\n",
        "data.dropna(inplace=True)  # Remove any rows with missing values\n",
        "data = data[['Abstract', 'Summarized Abstract']]  # Select the relevant columns\n",
        "\n",
        "# Split data into training (75%) and test (25%)\n",
        "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
        "\n",
        "# Tokenization and padding for text data\n",
        "tokenizer = Tokenizer(num_words=5000)  # You can adjust the num_words parameter\n",
        "tokenizer.fit_on_texts(train_data['Abstract'])\n",
        "X_train = tokenizer.texts_to_sequences(train_data['Abstract'])\n",
        "X_test = tokenizer.texts_to_sequences(test_data['Abstract'])\n",
        "max_len = 100  # You can adjust this based on your data\n",
        "X_train = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')\n",
        "X_test = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')\n",
        "\n",
        "# Tokenize and pad the target data (Summarized Abstract)\n",
        "target_tokenizer = Tokenizer(num_words=5000)  # You can adjust the num_words parameter\n",
        "target_tokenizer.fit_on_texts(train_data['Summarized Abstract'])\n",
        "y_train = target_tokenizer.texts_to_sequences(train_data['Summarized Abstract'])\n",
        "y_test = target_tokenizer.texts_to_sequences(test_data['Summarized Abstract'])\n",
        "max_summary_len = 50  # You can adjust this based on your data\n",
        "y_train = pad_sequences(y_train, maxlen=max_summary_len, padding='post', truncating='post')\n",
        "y_test = pad_sequences(y_test, maxlen=max_summary_len, padding='post', truncating='post')\n",
        "\n",
        "# Get the vocabulary size for the output layer\n",
        "vocabulary_size = len(target_tokenizer.word_index) + 1\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=5000, output_dim=1, input_length=max_len),\n",
        "    tf.keras.layers.Conv1D(128, 5, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
        "    tf.keras.layers.Conv1D(64, 5, activation='relu'),\n",
        "    tf.keras.layers.GlobalMaxPooling1D(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),  # Adding dropout for regularization\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(50, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=16)\n",
        "\n",
        "# Generate predicted summaries for the test data\n",
        "predicted_summaries = model.predict(X_test)\n",
        "\n",
        "# Convert sequences back to text\n",
        "predicted_summaries_text = [target_tokenizer.sequences_to_texts([seq])[0] for seq in predicted_summaries]\n",
        "actual_summaries_text = [target_tokenizer.sequences_to_texts([seq])[0] for seq in y_test]\n",
        "\n",
        "# # Calculate ROUGE score\n",
        "# rouge_score = corpus_bleu([[summary.split()] for summary in actual_summaries_text], [summary.split() for summary in predicted_summaries_text])\n",
        "\n",
        "# print(\"ROUGE Score:\", rouge_score)\n",
        "\n",
        "from nltk.translate.bleu_score import corpus_bleu, sentence_bleu\n",
        "\n",
        "# Convert sequences back to text for references and hypotheses\n",
        "references = [summary.split() for summary in actual_summaries_text]\n",
        "hypotheses = [summary.split() for summary in predicted_summaries_text]\n",
        "\n",
        "# Calculate ROUGE scores\n",
        "rouge_1 = corpus_bleu(references, hypotheses, weights=(1, 0, 0, 0))\n",
        "rouge_2 = corpus_bleu(references, hypotheses, weights=(0, 1, 0, 0))\n",
        "rouge_l = corpus_bleu(references, hypotheses, weights=(0, 0, 1, 0))\n",
        "rouge_lsum = corpus_bleu(references, hypotheses, weights=(0.25, 0.25, 0.25, 0.25))\n",
        "\n",
        "print(\"ROUGE-1:\", rouge_1)\n",
        "print(\"ROUGE-2:\", rouge_2)\n",
        "print(\"ROUGE-L:\", rouge_l)\n",
        "print(\"ROUGE-Lsum:\", rouge_lsum)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "t9zCKJUdQkwJ",
        "outputId": "c2c24bb9-6ae3-4c0b-dbea-daa131f86f3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "3/3 [==============================] - 2s 15ms/step - loss: 59254.4297\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 59247.7500\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 59241.7422\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 59244.9297\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 59268.5430\n",
            "1/1 [==============================] - 0s 451ms/step\n",
            "ROUGE-1: 0\n",
            "ROUGE-2: 0\n",
            "ROUGE-L: 0\n",
            "ROUGE-Lsum: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_excel('/content/drive/MyDrive/idp_dataset/pubmed_abstracts_clinicaltextrouge.xlsx')\n",
        "\n",
        "# Preprocessing\n",
        "data.dropna(inplace=True)  # Remove any rows with missing values\n",
        "data = data[['Abstract', 'Summarized Abstract']]  # Select the relevant columns\n",
        "\n",
        "# Split data into training (75%) and test (25%)\n",
        "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
        "\n",
        "# Tokenization and padding for text data\n",
        "tokenizer = Tokenizer(num_words=5000)  # Add an out-of-vocabulary token\n",
        "tokenizer.fit_on_texts(train_data['Abstract'])\n",
        "X_train = tokenizer.texts_to_sequences(train_data['Abstract'])\n",
        "X_test = tokenizer.texts_to_sequences(test_data['Abstract'])\n",
        "max_len = 100  # You can adjust this based on your data\n",
        "X_train = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')\n",
        "X_test = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')\n",
        "\n",
        "# Tokenize and pad the target data (Summarized Abstract)\n",
        "target_tokenizer = Tokenizer(num_words=5000)  # Add an out-of-vocabulary token\n",
        "target_tokenizer.fit_on_texts(train_data['Summarized Abstract'])\n",
        "y_train = target_tokenizer.texts_to_sequences(train_data['Summarized Abstract'])\n",
        "y_test = target_tokenizer.texts_to_sequences(test_data['Summarized Abstract'])\n",
        "max_summary_len = 50  # You can adjust this based on your data\n",
        "y_train = pad_sequences(y_train, maxlen=max_summary_len, padding='post', truncating='post')\n",
        "y_test = pad_sequences(y_test, maxlen=max_summary_len, padding='post', truncating='post')\n",
        "\n",
        "# Build a sequence-to-sequence CNN model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128, input_length=max_len),\n",
        "    tf.keras.layers.Conv1D(128, 5, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
        "    tf.keras.layers.Conv1D(64, 5, activation='relu'),\n",
        "    tf.keras.layers.GlobalMaxPooling1D(),\n",
        "    tf.keras.layers.RepeatVector(max_summary_len),  # Match encoder and decoder lengths\n",
        "    tf.keras.layers.LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2),  # Added dropout\n",
        "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(len(target_tokenizer.word_index) + 1, activation='softmax'))\n",
        "])\n",
        "\n",
        "# Compile the model with 'sparse_categorical_crossentropy' loss\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy')  # Adjusted learning rate\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=16)  # Increased epochs\n",
        "\n",
        "# Generate predicted summaries for the test data\n",
        "predicted_summaries = model.predict(X_test)\n",
        "\n",
        "\n",
        "# Implement beam search\n",
        "def beam_search_decoder(data, k):\n",
        "    sequences = [[list(), 1.0]]\n",
        "    for row in data:\n",
        "        all_candidates = list()\n",
        "        for i in range(len(sequences)):\n",
        "            seq, score = sequences[i]\n",
        "            for j in range(len(row)):\n",
        "                candidate = [seq + [j], score * -np.log(row[j])]\n",
        "                all_candidates.append(candidate)\n",
        "        ordered = sorted(all_candidates, key=lambda tup: tup[1])\n",
        "        sequences = ordered[:k]\n",
        "    return sequences\n",
        "\n",
        "# Perform beam search for each example in the test data\n",
        "beam_search_results = [beam_search_decoder(sample, k=3) for sample in predicted_summaries]\n",
        "\n",
        "# Convert sequences back to text and print examples\n",
        "for i in range(10):  # You can change the range to print more examples\n",
        "    actual_summary = \" \".join([target_tokenizer.index_word.get(word, \"\") for word in y_test[i] if word != 0])\n",
        "    predicted_summaries_text = []\n",
        "    for beam_result in beam_search_results[i]:\n",
        "        predicted_summary = \" \".join([target_tokenizer.index_word.get(word, \"\") for word in beam_result[0] if word != 0])\n",
        "        predicted_summaries_text.append(predicted_summary)\n",
        "    print(f\"Example - Actual Summary: {actual_summary}\")\n",
        "    print(f\"Example - Predicted Summaries: {predicted_summaries_text}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyyJdq3WmI0F",
        "outputId": "f12d0851-5f68-467b-c889-34a94f5dc37d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "3/3 [==============================] - 5s 139ms/step - loss: 7.1075\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 0s 143ms/step - loss: 7.0780\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 0s 140ms/step - loss: 6.9904\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 0s 148ms/step - loss: 6.7980\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 0s 155ms/step - loss: 6.5818\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 0s 162ms/step - loss: 6.3875\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 0s 150ms/step - loss: 6.2258\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 0s 146ms/step - loss: 6.1283\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 0s 148ms/step - loss: 6.1034\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 0s 148ms/step - loss: 6.0969\n",
            "1/1 [==============================] - 0s 321ms/step\n",
            "Example - Actual Summary: are the primary for the of and and models have in understanding these however the of a such as a should factors this scoping review aims to identify and the most factors as well as for of and\n",
            "Example - Predicted Summaries: ['the of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of', 'the the of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of']\n",
            "\n",
            "Example - Actual Summary: the of clinical is a before more natural language processing models that high accuracy for 1 experience a large of accuracy when to the of this study is to develop methods that clinical the with improved we found improved models only when with in samples improving the score from 0\n",
            "Example - Predicted Summaries: ['the of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of', 'the the of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of']\n",
            "\n",
            "Example - Actual Summary: the prevention of for patients with is still a great in clinical practice there are studies that to search for strategies to the and life for these patients we aim to the efficacy between different reported treatments by meta analysis most of the studies were high quality with low bias\n",
            "Example - Predicted Summaries: ['the of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of', 'the of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of the']\n",
            "\n",
            "Example - Actual Summary: large language models problems via text gpt 4 outperformed chatgpt in from free text reports on cancer it also had a lower rate of 1 7 7 4 9 the study included patients underwent cancer follow up between 2021 and\n",
            "Example - Predicted Summaries: ['the of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of', 'the the of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of']\n",
            "\n",
            "Example - Actual Summary: is a natural found in recent studies have shown that effects against a of cancer types this review a comprehensive overview of the current research and new perspectives on effect it may facilitate the of novel for cancer treatment the need for further clinical and clinical studies to evaluate its\n",
            "Example - Predicted Summaries: ['the of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of', 'the the of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of']\n",
            "\n",
            "Example - Actual Summary: natural language processing nlp can be used to free text in medical nlp was designed using lists based and decision tree learning it performed better on a more structured format than an unstructured one the study the design of an nlp based approach for evaluation of free text in the\n",
            "Example - Predicted Summaries: ['the of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of', 'the the of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of']\n",
            "\n",
            "Example - Actual Summary: the main of this were the clinical and the evaluation of conditions including pain and function the of patients with should include a method of and the degree of the value of for was and findings the routine of or testing is not recommended\n",
            "Example - Predicted Summaries: ['the of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of', 'the the of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of']\n",
            "\n",
            "Example - Actual Summary: study compared in to control was with laser six and six control               23 in the study different and of were found to be significantly different for the different conditions\n",
            "Example - Predicted Summaries: ['the of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of', 'the the of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of']\n",
            "\n",
            "Example - Actual Summary: use was as no use or use across 1 2 or 4 the incidence rate of use increased significantly with the study that may be an part of a specific of risk future studies should include measures of and to better the variability in back to online back to the\n",
            "Example - Predicted Summaries: ['the of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of', 'the the of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of']\n",
            "\n",
            "Example - Actual Summary: in fast for the               time in an improved understanding of is necessary as these may and risk associated with fast 1 were screened and full text articles were to determine whether they results were reported studies investigating of fast and features age and\n",
            "Example - Predicted Summaries: ['the of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of', 'of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of', 'the the of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **RNN**"
      ],
      "metadata": {
        "id": "gju0zGOHfjdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_excel('/content/drive/MyDrive/idp_dataset/pubmed_abstracts_clinicaltextrouge.xlsx')\n",
        "\n",
        "# Preprocessing\n",
        "data.dropna(inplace=True)  # Remove any rows with missing values\n",
        "data = data[['Abstract', 'Summarized Abstract']]  # Select the relevant columns\n",
        "\n",
        "# Split data into training (75%) and test (25%)\n",
        "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
        "\n",
        "# Tokenization and padding for text data\n",
        "tokenizer = Tokenizer(num_words=5000)  # You can adjust the num_words parameter\n",
        "tokenizer.fit_on_texts(train_data['Abstract'])\n",
        "X_train = tokenizer.texts_to_sequences(train_data['Abstract'])\n",
        "X_test = tokenizer.texts_to_sequences(test_data['Abstract'])\n",
        "max_len = 100  # You can adjust this based on your data\n",
        "X_train = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')\n",
        "X_test = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')\n",
        "\n",
        "# Tokenize and pad the target data (Summarized Abstract)\n",
        "target_tokenizer = Tokenizer(num_words=5000)  # You can adjust the num_words parameter\n",
        "target_tokenizer.fit_on_texts(train_data['Summarized Abstract'])\n",
        "y_train = target_tokenizer.texts_to_sequences(train_data['Summarized Abstract'])\n",
        "y_test = target_tokenizer.texts_to_sequences(test_data['Summarized Abstract'])\n",
        "max_summary_len = 100  # You can adjust this based on your data\n",
        "y_train = pad_sequences(y_train, maxlen=max_summary_len, padding='post', truncating='post')\n",
        "y_test = pad_sequences(y_test, maxlen=max_summary_len, padding='post', truncating='post')\n",
        "\n",
        "# Build and compile the RNN model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=5000, output_dim=100, input_length=max_len),\n",
        "    tf.keras.layers.SimpleRNN(256,  activation='elu',  return_sequences=True),\n",
        "    tf.keras.layers.SimpleRNN(256,  activation='elu',  return_sequences=True),\n",
        "    tf.keras.layers.SimpleRNN(256,  activation='elu',  return_sequences=True),\n",
        "    tf.keras.layers.SimpleRNN(256,  activation='elu',  return_sequences=True),\n",
        "    tf.keras.layers.SimpleRNN(256,  activation='elu',  return_sequences=True),\n",
        "\n",
        "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(5000, activation='softmax'))\n",
        "])\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=16)\n",
        "\n",
        "# Generate predicted summaries for the test data\n",
        "predicted_summaries = model.predict(X_test)\n",
        "\n",
        "# Convert sequences back to text\n",
        "# Convert sequences back to text\n",
        "predicted_summaries_text = []\n",
        "for seq in predicted_summaries:\n",
        "    text_seq = [str(word) for word in seq]\n",
        "    text_seq = ' '.join(text_seq).strip()\n",
        "    predicted_summaries_text.append(text_seq)\n",
        "\n",
        "actual_summaries_text = []\n",
        "for seq in y_test:\n",
        "    text_seq = [str(word) for word in seq]\n",
        "    text_seq = ' '.join(text_seq).strip()\n",
        "    actual_summaries_text.append(text_seq)\n",
        "\n",
        "\n",
        "# Calculate ROUGE scores\n",
        "from nltk.translate.bleu_score import corpus_bleu, sentence_bleu\n",
        "\n",
        "# Calculate ROUGE scores\n",
        "rouge_1 = corpus_bleu([actual_summaries_text], [predicted_summaries_text], weights=(1, 0, 0, 0))\n",
        "rouge_2 = corpus_bleu([actual_summaries_text], [predicted_summaries_text], weights=(0, 1, 0, 0))\n",
        "rouge_l = corpus_bleu([actual_summaries_text], [predicted_summaries_text], weights=(0, 0, 1, 0))\n",
        "rouge_lsum = corpus_bleu([actual_summaries_text], [predicted_summaries_text], weights=(0.25, 0.25, 0.25, 0.25))\n",
        "\n",
        "print(\"ROUGE-1:\", rouge_1)\n",
        "print(\"ROUGE-2:\", rouge_2)\n",
        "print(\"ROUGE-L:\", rouge_l)\n",
        "print(\"ROUGE-Lsum:\", rouge_lsum)\n"
      ],
      "metadata": {
        "id": "yCcUn1fBfnZy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7889e1e7-c408-4007-cc8e-fab96d47b624"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "3/3 [==============================] - 8s 579ms/step - loss: 8.2229 - accuracy: 0.0883\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 2s 558ms/step - loss: 7.1989 - accuracy: 0.1875\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 2s 558ms/step - loss: 5.9944 - accuracy: 0.1489\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 2s 559ms/step - loss: 5.7190 - accuracy: 0.1375\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 2s 736ms/step - loss: 5.4560 - accuracy: 0.1894\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "ROUGE-1: 0\n",
            "ROUGE-2: 0\n",
            "ROUGE-L: 0\n",
            "ROUGE-Lsum: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RNN print actual summary and predicted summary\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_excel('/content/drive/MyDrive/idp_dataset/pubmed_abstracts_clinicaltextrouge.xlsx')\n",
        "\n",
        "# Preprocessing\n",
        "data.dropna(inplace=True)  # Remove any rows with missing values\n",
        "data = data[['Abstract', 'Summarized Abstract']]  # Select the relevant columns\n",
        "\n",
        "# Split data into training (75%) and test (25%)\n",
        "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
        "\n",
        "# Tokenization and padding for text data\n",
        "tokenizer = Tokenizer(num_words=5000)  # You can adjust the num_words parameter\n",
        "tokenizer.fit_on_texts(train_data['Abstract'])\n",
        "X_train = tokenizer.texts_to_sequences(train_data['Abstract'])\n",
        "X_test = tokenizer.texts_to_sequences(test_data['Abstract'])\n",
        "max_len = 100  # You can adjust this based on your data\n",
        "X_train = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')\n",
        "X_test = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')\n",
        "\n",
        "# Tokenize and pad the target data (Summarized Abstract)\n",
        "target_tokenizer = Tokenizer(num_words=5000)  # You can adjust the num_words parameter\n",
        "target_tokenizer.fit_on_texts(train_data['Summarized Abstract'])\n",
        "y_train = target_tokenizer.texts_to_sequences(train_data['Summarized Abstract'])\n",
        "y_test = target_tokenizer.texts_to_sequences(test_data['Summarized Abstract'])\n",
        "max_summary_len = 100  # You can adjust this based on your data\n",
        "y_train = pad_sequences(y_train, maxlen=max_summary_len, padding='post', truncating='post')\n",
        "y_test = pad_sequences(y_test, maxlen=max_summary_len, padding='post', truncating='post')\n",
        "\n",
        "# Build and compile the RNN model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=5000, output_dim=100, input_length=max_len),\n",
        "    tf.keras.layers.SimpleRNN(256, activation='elu', return_sequences=True),\n",
        "    tf.keras.layers.SimpleRNN(256, activation='elu', return_sequences=True),\n",
        "    tf.keras.layers.SimpleRNN(256, activation='elu', return_sequences=True),\n",
        "    tf.keras.layers.SimpleRNN(256, activation='elu', return_sequences=True),\n",
        "    tf.keras.layers.SimpleRNN(256, activation='elu', return_sequences=True),\n",
        "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(5000, activation='softmax'))\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=16)\n",
        "\n",
        "# Generate predicted summaries for the test data\n",
        "predicted_summaries = model.predict(X_test)\n",
        "\n",
        "# Implement beam search\n",
        "def beam_search_decoder(data, k):\n",
        "    sequences = [[list(), 1.0]]\n",
        "    for row in data:\n",
        "        all_candidates = list()\n",
        "        for i in range(len(sequences)):\n",
        "            seq, score = sequences[i]\n",
        "            for j in range(len(row)):\n",
        "                candidate = [seq + [j], score * -np.log(row[j])]\n",
        "                all_candidates.append(candidate)\n",
        "        ordered = sorted(all_candidates, key=lambda tup: tup[1])\n",
        "        sequences = ordered[:k]\n",
        "    return sequences\n",
        "\n",
        "# Perform beam search for each example in the test data\n",
        "beam_search_results = [beam_search_decoder(sample, k=3) for sample in predicted_summaries]\n",
        "\n",
        "# Convert sequences back to text and print examples\n",
        "for i in range(10):  # You can change the range to print more examples\n",
        "    actual_summary = \" \".join([target_tokenizer.index_word.get(word, \"\") for word in y_test[i] if word != 0])\n",
        "    predicted_summaries_text = []\n",
        "    for beam_result in beam_search_results[i]:\n",
        "        predicted_summary = \" \".join([target_tokenizer.index_word.get(word, \"\") for word in beam_result[0] if word != 0])\n",
        "        predicted_summaries_text.append(predicted_summary)\n",
        "    print(f\"Example - Actual Summary: {actual_summary}\")\n",
        "    print(f\"Example - Predicted Summaries: {predicted_summaries_text}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTPYA6WAh_p6",
        "outputId": "b3d2de01-8418-4ca5-bb3c-ca4e2e9782f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "3/3 [==============================] - 6s 498ms/step - loss: 8.3963 - accuracy: 0.1025\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 2s 491ms/step - loss: 7.5932 - accuracy: 0.1881\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 2s 480ms/step - loss: 6.3830 - accuracy: 0.1867\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 2s 489ms/step - loss: 5.9049 - accuracy: 0.0875\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 2s 719ms/step - loss: 5.6405 - accuracy: 0.1886\n",
            "1/1 [==============================] - 1s 779ms/step\n",
            "Example - Actual Summary: are the primary for the of and and models have in understanding these however the of a such as a should factors this scoping review aims to identify and the most factors as well as for of and\n",
            "Example - Predicted Summaries: ['the the', 'to the', 'structured the']\n",
            "\n",
            "Example - Actual Summary: the of clinical is a before more natural language processing models that high accuracy for 1 experience a large of accuracy when to the of this study is to develop methods that clinical the with improved we found improved models only when with in samples improving the score from 0 to 0\n",
            "Example - Predicted Summaries: ['the', 'of', 'more']\n",
            "\n",
            "Example - Actual Summary: the prevention of for patients with is still a great in clinical practice there are studies that to search for strategies to the and life for these patients we aim to the efficacy between different reported treatments by meta analysis most of the studies were high quality with low bias and were when the of life\n",
            "Example - Predicted Summaries: ['the', '\\xa0', 'studies']\n",
            "\n",
            "Example - Actual Summary: large language models problems via text gpt 4 outperformed chatgpt in from free text reports on cancer it also had a lower rate of 1 7 7 4 9 the study included patients underwent cancer follow up between 2021 and\n",
            "Example - Predicted Summaries: ['', 'and', 'and']\n",
            "\n",
            "Example - Actual Summary: is a natural found in recent studies have shown that effects against a of cancer types this review a comprehensive overview of the current research and new perspectives on effect it may facilitate the of novel for cancer treatment the need for further clinical and clinical studies to evaluate its safety and efficacy further the authors conclude the study was published in the journal of cancer research\n",
            "Example - Predicted Summaries: ['to the', 'the the', 'studies the']\n",
            "\n",
            "Example - Actual Summary: natural language processing nlp can be used to free text in medical nlp was designed using lists based and decision tree learning it performed better on a more structured format than an unstructured one the study the design of an nlp based approach for evaluation of free text in the it a for further more nlp approaches models\n",
            "Example - Predicted Summaries: ['', 'and', 'and']\n",
            "\n",
            "Example - Actual Summary: the main of this were the clinical and the evaluation of conditions including pain and function the of patients with should include a method of and the degree of the value of for was and findings the routine of or testing is not recommended\n",
            "Example - Predicted Summaries: ['the the', 'to the', 'structured the']\n",
            "\n",
            "Example - Actual Summary: study compared in to control was with laser six and six control               23 in the study different and of were found to be significantly different for the different conditions\n",
            "Example - Predicted Summaries: ['the the', 'the', '\\xa0 the']\n",
            "\n",
            "Example - Actual Summary: use was as no use or use across 1 2 or 4 the incidence rate of use increased significantly with the study that may be an part of a specific of risk future studies should include measures of and to better the variability in back to online back to the from\n",
            "Example - Predicted Summaries: ['the', 'studies', 'and']\n",
            "\n",
            "Example - Actual Summary: in fast for the               time in an improved understanding of is necessary as these may and risk associated with fast 1 were screened and full text articles were to determine whether they results were reported studies investigating of fast and features age and characteristics\n",
            "Example - Predicted Summaries: ['', 'and', 'to']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LSTM**"
      ],
      "metadata": {
        "id": "SPfGcV8Knljy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_excel('/content/drive/MyDrive/idp_dataset/pubmed_abstracts_clinicaltextrouge.xlsx')\n",
        "\n",
        "# Preprocessing\n",
        "data.dropna(inplace=True)  # Remove any rows with missing values\n",
        "data = data[['Abstract', 'Summarized Abstract']]  # Select the relevant columns\n",
        "\n",
        "# Split data into training (75%) and test (25%)\n",
        "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
        "\n",
        "# Tokenization and padding for text data\n",
        "tokenizer = Tokenizer(num_words=5000)  # You can adjust the num_words parameter\n",
        "tokenizer.fit_on_texts(train_data['Abstract'])\n",
        "X_train = tokenizer.texts_to_sequences(train_data['Abstract'])\n",
        "X_test = tokenizer.texts_to_sequences(test_data['Abstract'])\n",
        "max_len = 100  # You can adjust this based on your data\n",
        "X_train = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')\n",
        "X_test = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')\n",
        "\n",
        "# Tokenize and pad the target data (Summarized Abstract)\n",
        "target_tokenizer = Tokenizer(num_words=5000)  # You can adjust the num_words parameter\n",
        "target_tokenizer.fit_on_texts(train_data['Summarized Abstract'])\n",
        "y_train = target_tokenizer.texts_to_sequences(train_data['Summarized Abstract'])\n",
        "y_test = target_tokenizer.texts_to_sequences(test_data['Summarized Abstract'])\n",
        "max_summary_len = 100  # You can adjust this based on your data\n",
        "y_train = pad_sequences(y_train, maxlen=max_summary_len, padding='post', truncating='post')\n",
        "y_test = pad_sequences(y_test, maxlen=max_summary_len, padding='post', truncating='post')\n",
        "\n",
        "# Build and compile the LSTM model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=5000, output_dim=100, input_length=max_len),\n",
        "    tf.keras.layers.LSTM(256, return_sequences=True, activation='relu'),\n",
        "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(5000, activation='softmax'))\n",
        "])\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=16)\n",
        "\n",
        "# Generate predicted summaries for the test data\n",
        "predicted_summaries = model.predict(X_test)\n",
        "\n",
        "# Convert sequences back to text\n",
        "predicted_summaries_text = []\n",
        "for seq in predicted_summaries:\n",
        "    text_seq = [str(word) for word in seq]\n",
        "    text_seq = ' '.join(text_seq).strip()\n",
        "    predicted_summaries_text.append(text_seq)\n",
        "\n",
        "actual_summaries_text = []\n",
        "for seq in y_test:\n",
        "    text_seq = [str(word) for word in seq]\n",
        "    text_seq = ' '.join(text_seq).strip()\n",
        "    actual_summaries_text.append(text_seq)\n",
        "\n",
        "\n",
        "# Calculate ROUGE scores\n",
        "from nltk.translate.bleu_score import corpus_bleu, sentence_bleu\n",
        "\n",
        "# Calculate ROUGE scores\n",
        "rouge_1 = corpus_bleu([actual_summaries_text], [predicted_summaries_text], weights=(1, 0, 0, 0))\n",
        "rouge_2 = corpus_bleu([actual_summaries_text], [predicted_summaries_text], weights=(0, 1, 0, 0))\n",
        "rouge_l = corpus_bleu([actual_summaries_text], [predicted_summaries_text], weights=(0, 0, 1, 0))\n",
        "rouge_lsum = corpus_bleu([actual_summaries_text], [predicted_summaries_text], weights=(0.25, 0.25, 0.25, 0.25))\n",
        "\n",
        "print(\"ROUGE-1:\", rouge_1)\n",
        "print(\"ROUGE-2:\", rouge_2)\n",
        "print(\"ROUGE-L:\", rouge_l)\n",
        "print(\"ROUGE-Lsum:\", rouge_lsum)\n"
      ],
      "metadata": {
        "id": "oRaPnZoxnrvF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db46fbf5-cb4f-4296-f708-9ee0623d452f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "3/3 [==============================] - 5s 493ms/step - loss: 8.5154 - accuracy: 0.0650\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 2s 488ms/step - loss: 8.5026 - accuracy: 0.1875\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 2s 500ms/step - loss: 8.4224 - accuracy: 0.1875\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 2s 484ms/step - loss: 8.1312 - accuracy: 0.1875\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 2s 477ms/step - loss: 7.7994 - accuracy: 0.1844\n",
            "1/1 [==============================] - 0s 451ms/step\n",
            "ROUGE-1: 0\n",
            "ROUGE-2: 0\n",
            "ROUGE-L: 0\n",
            "ROUGE-Lsum: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LSTM - PRINTING ACTUAL AND PREDICTED SUMMARIES TEXT\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_excel('/content/drive/MyDrive/idp_dataset/pubmed_abstracts_clinicaltextrouge.xlsx')\n",
        "\n",
        "# Preprocessing\n",
        "data.dropna(inplace=True)  # Remove any rows with missing values\n",
        "data = data[['Abstract', 'Summarized Abstract']]  # Select the relevant columns\n",
        "\n",
        "# Split data into training (75%) and test (25%)\n",
        "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
        "\n",
        "# Tokenization and padding for text data\n",
        "tokenizer = Tokenizer(num_words=5000)  # You can adjust the num_words parameter\n",
        "tokenizer.fit_on_texts(train_data['Abstract'])\n",
        "X_train = tokenizer.texts_to_sequences(train_data['Abstract'])\n",
        "X_test = tokenizer.texts_to_sequences(test_data['Abstract'])\n",
        "max_len = 100  # You can adjust this based on your data\n",
        "X_train = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')\n",
        "X_test = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')\n",
        "\n",
        "# Tokenize and pad the target data (Summarized Abstract)\n",
        "target_tokenizer = Tokenizer(num_words=5000)  # You can adjust the num_words parameter\n",
        "target_tokenizer.fit_on_texts(train_data['Summarized Abstract'])\n",
        "y_train = target_tokenizer.texts_to_sequences(train_data['Summarized Abstract'])\n",
        "y_test = target_tokenizer.texts_to_sequences(test_data['Summarized Abstract'])\n",
        "max_summary_len = 100  # Match the max_len of X\n",
        "y_train = pad_sequences(y_train, maxlen=max_summary_len, padding='post', truncating='post')\n",
        "y_test = pad_sequences(y_test, maxlen=max_summary_len, padding='post', truncating='post')\n",
        "\n",
        "# Build and compile the LSTM model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=5000, output_dim=100, input_length=max_len),\n",
        "    tf.keras.layers.LSTM(256, return_sequences=True, activation='relu'),\n",
        "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(5000, activation='softmax'))\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=16)\n",
        "\n",
        "# Generate predicted summaries for the test data\n",
        "predicted_summaries = model.predict(X_test)\n",
        "\n",
        "# Implement beam search\n",
        "def beam_search_decoder(data, k):\n",
        "    sequences = [[list(), 1.0]]\n",
        "    for row in data:\n",
        "        all_candidates = list()\n",
        "        for i in range(len(sequences)):\n",
        "            seq, score = sequences[i]\n",
        "            for j in range(len(row)):\n",
        "                candidate = [seq + [j], score * -np.log(row[j])]\n",
        "                all_candidates.append(candidate)\n",
        "        ordered = sorted(all_candidates, key=lambda tup: tup[1])\n",
        "        sequences = ordered[:k]\n",
        "    return sequences\n",
        "\n",
        "# Perform beam search for each example in the test data\n",
        "beam_search_results = [beam_search_decoder(sample, k=3) for sample in predicted_summaries]\n",
        "\n",
        "# Convert sequences back to text and print examples\n",
        "for i in range(10):  # You can change the range to print more examples\n",
        "    actual_summary = \" \".join([target_tokenizer.index_word.get(word, \"\") for word in y_test[i] if word != 0])\n",
        "    predicted_summaries_text = []\n",
        "    for beam_result in beam_search_results[i]:\n",
        "        predicted_summary = \" \".join([target_tokenizer.index_word.get(word, \"\") for word in beam_result[0] if word != 0])\n",
        "        predicted_summaries_text.append(predicted_summary)\n",
        "    print(f\"Example - Actual Summary: {actual_summary}\")\n",
        "    print(f\"Example - Predicted Summaries: {predicted_summaries_text}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBD2i-41uK0h",
        "outputId": "c8ec9818-447d-443c-8e4d-f563b64b54a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "3/3 [==============================] - 4s 499ms/step - loss: 8.5156 - accuracy: 0.0214\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 2s 500ms/step - loss: 8.5037 - accuracy: 0.1875\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 2s 678ms/step - loss: 8.4708 - accuracy: 0.1878\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 3s 818ms/step - loss: 7.8631 - accuracy: 0.1878\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 3s 700ms/step - loss: 7.7691 - accuracy: 0.1858\n",
            "1/1 [==============================] - 0s 290ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-fb4732a7dfad>:61: RuntimeWarning: divide by zero encountered in log\n",
            "  candidate = [seq + [j], score * -np.log(row[j])]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example - Actual Summary: are the primary for the of and and models have in understanding these however the of a such as a should factors this scoping review aims to identify and the most factors as well as for of and\n",
            "Example - Predicted Summaries: ['in the the the is the the', 'in the the is the the', 'was the the the is the the']\n",
            "\n",
            "Example - Actual Summary: the of clinical is a before more natural language processing models that high accuracy for 1 experience a large of accuracy when to the of this study is to develop methods that clinical the with improved we found improved models only when with in samples improving the score from 0 to 0\n",
            "Example - Predicted Summaries: ['the the the the the the the the the the is is is', 'the the the the the the the the the is is is', 'the the the the the the the the the is is is']\n",
            "\n",
            "Example - Actual Summary: the prevention of for patients with is still a great in clinical practice there are studies that to search for strategies to the and life for these patients we aim to the efficacy between different reported treatments by meta analysis most of the studies were high quality with low bias and were when the of life\n",
            "Example - Predicted Summaries: ['to to the the the the the', 'to the the the the the the', 'the to the the the the the']\n",
            "\n",
            "Example - Actual Summary: large language models problems via text gpt 4 outperformed chatgpt in from free text reports on cancer it also had a lower rate of 1 7 7 4 9 the study included patients underwent cancer follow up between 2021 and\n",
            "Example - Predicted Summaries: ['was the the the the the the the the the the the the the is is of the the', 'was was the the the the the the the the the the the the is is of the the', 'was the the the the the the the the the the the the the the is is of the the']\n",
            "\n",
            "Example - Actual Summary: is a natural found in recent studies have shown that effects against a of cancer types this review a comprehensive overview of the current research and new perspectives on effect it may facilitate the of novel for cancer treatment the need for further clinical and clinical studies to evaluate its safety and efficacy further the authors conclude the study was published in the journal of cancer research\n",
            "Example - Predicted Summaries: ['was to to to the data is is the data the the', 'the to to to the data is is the data the the', 'was to to to the the data is is the data the the']\n",
            "\n",
            "Example - Actual Summary: natural language processing nlp can be used to free text in medical nlp was designed using lists based and decision tree learning it performed better on a more structured format than an unstructured one the study the design of an nlp based approach for evaluation of free text in the it a for further more nlp approaches models\n",
            "Example - Predicted Summaries: ['was the the the the the the is the is the the', 'was the the the the the the the is the is the the', 'the the the the the the the is the is the the']\n",
            "\n",
            "Example - Actual Summary: the main of this were the clinical and the evaluation of conditions including pain and function the of patients with should include a method of and the degree of the value of for was and findings the routine of or testing is not recommended\n",
            "Example - Predicted Summaries: ['in the the is is is the the', 'in to the the is is is the the', 'was the the is is is the the']\n",
            "\n",
            "Example - Actual Summary: study compared in to control was with laser six and six control               23 in the study different and of were found to be significantly different for the different conditions\n",
            "Example - Predicted Summaries: ['to the the the the the is the the the the \\xa0 the is the', 'the the the the the the is the the the the \\xa0 the is the', 'was the the the the the is the the the the \\xa0 the is the']\n",
            "\n",
            "Example - Actual Summary: use was as no use or use across 1 2 or 4 the incidence rate of use increased significantly with the study that may be an part of a specific of risk future studies should include measures of and to better the variability in back to online back to the from\n",
            "Example - Predicted Summaries: ['the the the the the the the the the the the data \\xa0 the', 'to the the the the the the the the the the data \\xa0 the', 'the the the the the the the the the the data \\xa0 the']\n",
            "\n",
            "Example - Actual Summary: in fast for the               time in an improved understanding of is necessary as these may and risk associated with fast 1 were screened and full text articles were to determine whether they results were reported studies investigating of fast and features age and characteristics\n",
            "Example - Predicted Summaries: ['was the the the be the is the the the the is the the the the the is', 'was the the the the be the is the the the the is the the the the the is', 'the the the the be the is the the the the is the the the the the is']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CNN** + RNN"
      ],
      "metadata": {
        "id": "743lmRGxoDFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_excel('/content/drive/MyDrive/idp_dataset/pubmed_abstracts_clinicaltextrouge.xlsx')\n",
        "\n",
        "# Preprocessing\n",
        "data.dropna(inplace=True)  # Remove any rows with missing values\n",
        "data = data[['Abstract', 'Summarized Abstract']]  # Select the relevant columns\n",
        "\n",
        "# Split data into training (75%) and test (25%)\n",
        "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
        "\n",
        "# Tokenization and padding for text data\n",
        "tokenizer = Tokenizer(num_words=5000)  # You can adjust the num_words parameter\n",
        "tokenizer.fit_on_texts(train_data['Abstract'])\n",
        "X_train = tokenizer.texts_to_sequences(train_data['Abstract'])\n",
        "X_test = tokenizer.texts_to_sequences(test_data['Abstract'])\n",
        "max_len = 100  # You can adjust this based on your data\n",
        "X_train = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')\n",
        "X_test = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')\n",
        "\n",
        "# Tokenize and pad the target data (Summarized Abstract)\n",
        "target_tokenizer = Tokenizer(num_words=5000)  # You can adjust the num_words parameter\n",
        "target_tokenizer.fit_on_texts(train_data['Summarized Abstract'])\n",
        "y_train = target_tokenizer.texts_to_sequences(train_data['Summarized Abstract'])\n",
        "y_test = target_tokenizer.texts_to_sequences(test_data['Summarized Abstract'])\n",
        "max_summary_len = 48  # You can adjust this based on your data\n",
        "\n",
        "# Padding or truncating the input sequences\n",
        "X_train = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')\n",
        "X_test = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')\n",
        "\n",
        "# Padding or truncating the target sequences\n",
        "y_train = pad_sequences(y_train, maxlen=max_summary_len, padding='post', truncating='post')\n",
        "y_test = pad_sequences(y_test, maxlen=max_summary_len, padding='post', truncating='post')\n",
        "\n",
        "\n",
        "# Build and compile the CNN-RNN model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=5000, output_dim=100, input_length=max_len),\n",
        "    tf.keras.layers.Conv1D(128, 5, activation='relu'),  # You can adjust the filter size and number of filters\n",
        "    tf.keras.layers.MaxPooling1D(2),\n",
        "    tf.keras.layers.LSTM(256, activation='relu', return_sequences=True),\n",
        "    tf.keras.layers.LSTM(256, activation='relu', return_sequences=True),\n",
        "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(5000, activation='softmax'))\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=16)\n",
        "\n",
        "# Generate predicted summaries for the test data\n",
        "predicted_summaries = model.predict(X_test)\n",
        "\n",
        "# Convert sequences back to text\n",
        "predicted_summaries_text = []\n",
        "for seq in predicted_summaries:\n",
        "    text_seq = [str(word) for word in seq]\n",
        "    text_seq = ' '.join(text_seq).strip()\n",
        "    predicted_summaries_text.append(text_seq)\n",
        "\n",
        "actual_summaries_text = []\n",
        "for seq in y_test:\n",
        "    text_seq = [str(word) for word in seq]\n",
        "    text_seq = ' '.join(text_seq).strip()\n",
        "    actual_summaries_text.append(text_seq)\n",
        "\n",
        "# Calculate ROUGE scores\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "# Calculate ROUGE scores\n",
        "rouge_1 = corpus_bleu([actual_summaries_text], [predicted_summaries_text], weights=(1, 0, 0, 0))\n",
        "rouge_2 = corpus_bleu([actual_summaries_text], [predicted_summaries_text], weights=(0, 1, 0, 0))\n",
        "rouge_l = corpus_bleu([actual_summaries_text], [predicted_summaries_text], weights=(0, 0, 1, 0))\n",
        "rouge_lsum = corpus_bleu([actual_summaries_text], [predicted_summaries_text], weights=(0.25, 0.25, 0.25, 0.25))\n",
        "\n",
        "print(\"ROUGE-1:\", rouge_1)\n",
        "print(\"ROUGE-2:\", rouge_2)\n",
        "print(\"ROUGE-L:\", rouge_l)\n",
        "print(\"ROUGE-Lsum:\", rouge_lsum)\n"
      ],
      "metadata": {
        "id": "nwFrGYTcoGRO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc256eaf-5d1c-4468-9a7a-fe3c2c5a0624"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "3/3 [==============================] - 10s 389ms/step - loss: 8.5162 - accuracy: 0.0087\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 1s 393ms/step - loss: 8.5063 - accuracy: 0.0527\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 1s 401ms/step - loss: 8.4577 - accuracy: 0.0492\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 1s 383ms/step - loss: 8.9919 - accuracy: 0.0440\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 1s 387ms/step - loss: 8.1469 - accuracy: 0.0475\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "ROUGE-1: 0\n",
            "ROUGE-2: 0\n",
            "ROUGE-L: 0\n",
            "ROUGE-Lsum: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cnn + rnn - PRINTING ACTUAL AND PREDICTED SUMMARIES\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_excel('/content/drive/MyDrive/idp_dataset/pubmed_abstracts_clinicaltextrouge.xlsx')\n",
        "\n",
        "# Preprocessing\n",
        "data.dropna(inplace=True)  # Remove any rows with missing values\n",
        "data = data[['Abstract', 'Summarized Abstract']]  # Select the relevant columns\n",
        "\n",
        "# Split data into training (75%) and test (25%)\n",
        "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
        "\n",
        "# Tokenization and padding for text data\n",
        "tokenizer = Tokenizer(num_words=5000)  # You can adjust the num_words parameter\n",
        "tokenizer.fit_on_texts(train_data['Abstract'])\n",
        "X_train = tokenizer.texts_to_sequences(train_data['Abstract'])\n",
        "X_test = tokenizer.texts_to_sequences(test_data['Abstract'])\n",
        "max_len = 100  # You can adjust this based on your data\n",
        "X_train = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')\n",
        "X_test = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')\n",
        "\n",
        "# Tokenize and pad the target data (Summarized Abstract)\n",
        "target_tokenizer = Tokenizer(num_words=5000)  # You can adjust the num_words parameter\n",
        "target_tokenizer.fit_on_texts(train_data['Summarized Abstract'])\n",
        "y_train = target_tokenizer.texts_to_sequences(train_data['Summarized Abstract'])\n",
        "y_test = target_tokenizer.texts_to_sequences(test_data['Summarized Abstract'])\n",
        "max_summary_len = 48  # You can adjust this based on your data\n",
        "\n",
        "# Padding or truncating the input sequences\n",
        "X_train = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')\n",
        "X_test = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')\n",
        "\n",
        "# Padding or truncating the target sequences\n",
        "y_train = pad_sequences(y_train, maxlen=max_summary_len, padding='post', truncating='post')\n",
        "y_test = pad_sequences(y_test, maxlen=max_summary_len, padding='post', truncating='post')\n",
        "\n",
        "\n",
        "# Build and compile the CNN-RNN model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=5000, output_dim=100, input_length=max_len),\n",
        "    tf.keras.layers.Conv1D(128, 5, activation='relu'),  # You can adjust the filter size and number of filters\n",
        "    tf.keras.layers.MaxPooling1D(2),\n",
        "    tf.keras.layers.LSTM(256, activation='relu', return_sequences=True),\n",
        "    tf.keras.layers.LSTM(256, activation='relu', return_sequences=True),\n",
        "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(5000, activation='softmax'))\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=16)\n",
        "\n",
        "# Generate predicted summaries for the test data\n",
        "predicted_summaries = model.predict(X_test)\n",
        "\n",
        "# Implement beam search\n",
        "def beam_search_decoder(data, k):\n",
        "    sequences = [[list(), 1.0]]\n",
        "    for row in data:\n",
        "        all_candidates = list()\n",
        "        for i in range(len(sequences)):\n",
        "            seq, score = sequences[i]\n",
        "            for j in range(len(row)):\n",
        "                candidate = [seq + [j], score * -np.log(row[j])]\n",
        "                all_candidates.append(candidate)\n",
        "        ordered = sorted(all_candidates, key=lambda tup: tup[1])\n",
        "        sequences = ordered[:k]\n",
        "    return sequences\n",
        "\n",
        "# Perform beam search for each example in the test data\n",
        "beam_search_results = [beam_search_decoder(sample, k=3) for sample in predicted_summaries]\n",
        "\n",
        "# Convert sequences back to text and print examples\n",
        "for i in range(10):  # You can change the range to print more examples\n",
        "    actual_summary = \" \".join([target_tokenizer.index_word.get(word, \"\") for word in y_test[i] if word != 0])\n",
        "    predicted_summaries_text = []\n",
        "    for beam_result in beam_search_results[i]:\n",
        "        predicted_summary = \" \".join([target_tokenizer.index_word.get(word, \"\") for word in beam_result[0] if word != 0])\n",
        "        predicted_summaries_text.append(predicted_summary)\n",
        "    print(f\"Example - Actual Summary: {actual_summary}\")\n",
        "    print(f\"Example - Predicted Summaries: {predicted_summaries_text}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P25xuhj84o1Y",
        "outputId": "67618a84-09ec-4f03-bc95-7c87a3149046"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "3/3 [==============================] - 6s 395ms/step - loss: 8.5163 - accuracy: 0.0237\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 1s 408ms/step - loss: 8.5060 - accuracy: 0.0492\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 1s 507ms/step - loss: 8.4578 - accuracy: 0.0492\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 2s 646ms/step - loss: 8.9925 - accuracy: 0.0480\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 2s 653ms/step - loss: 8.0159 - accuracy: 0.0394\n",
            "1/1 [==============================] - 1s 617ms/step\n",
            "Example - Actual Summary: are the primary for the of and and models have in understanding these however the of a such as a should factors this scoping review aims to identify and the most factors as well as for of and\n",
            "Example - Predicted Summaries: ['and the the the the and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and', 'the the the the the and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and', 'and and the the the and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and']\n",
            "\n",
            "Example - Actual Summary: the of clinical is a before more natural language processing models that high accuracy for 1 experience a large of accuracy when to the of this study is to develop methods that clinical the with improved we found improved models only when with in samples improving the score\n",
            "Example - Predicted Summaries: ['and the and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and', 'and the the and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and', 'the the and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and']\n",
            "\n",
            "Example - Actual Summary: the prevention of for patients with is still a great in clinical practice there are studies that to search for strategies to the and life for these patients we aim to the efficacy between different reported treatments by meta analysis most of the studies were high quality with\n",
            "Example - Predicted Summaries: ['and the and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and', 'the the and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and', 'and the the and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and']\n",
            "\n",
            "Example - Actual Summary: large language models problems via text gpt 4 outperformed chatgpt in from free text reports on cancer it also had a lower rate of 1 7 7 4 9 the study included patients underwent cancer follow up between 2021 and\n",
            "Example - Predicted Summaries: ['and the the the the and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and', 'and and the the the and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and', 'the the the the the and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and']\n",
            "\n",
            "Example - Actual Summary: is a natural found in recent studies have shown that effects against a of cancer types this review a comprehensive overview of the current research and new perspectives on effect it may facilitate the of novel for cancer treatment the need for further clinical and clinical studies to\n",
            "Example - Predicted Summaries: ['and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and', 'and the and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and', 'and and the and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and']\n",
            "\n",
            "Example - Actual Summary: natural language processing nlp can be used to free text in medical nlp was designed using lists based and decision tree learning it performed better on a more structured format than an unstructured one the study the design of an nlp based approach for evaluation of free text\n",
            "Example - Predicted Summaries: ['and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and', 'and the and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and', 'the and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and']\n",
            "\n",
            "Example - Actual Summary: the main of this were the clinical and the evaluation of conditions including pain and function the of patients with should include a method of and the degree of the value of for was and findings the routine of or testing is not recommended\n",
            "Example - Predicted Summaries: ['and the the the the and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and', 'and and the the the and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and', 'and the the the the the and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and']\n",
            "\n",
            "Example - Actual Summary: study compared in to control was with laser six and six control               23 in the study different and of were found to be significantly different for the different conditions\n",
            "Example - Predicted Summaries: ['the the the the the and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and', 'and the the the the and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and', 'the the the the and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and']\n",
            "\n",
            "Example - Actual Summary: use was as no use or use across 1 2 or 4 the incidence rate of use increased significantly with the study that may be an part of a specific of risk future studies should include measures of and to better the variability in back to online back\n",
            "Example - Predicted Summaries: ['and the the the the and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and', 'the the the the the and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and', 'and the the the and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and']\n",
            "\n",
            "Example - Actual Summary: in fast for the               time in an improved understanding of is necessary as these may and risk associated with fast 1 were screened and full text articles were to determine whether they results were reported studies investigating of fast and features\n",
            "Example - Predicted Summaries: ['and the the the and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and', 'the the the the and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and', 'and and the the and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**# biLSTM**"
      ],
      "metadata": {
        "id": "SeGIzHCHwjZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_excel('/content/drive/MyDrive/idp_dataset/pubmed_abstracts_clinicaltextrouge.xlsx')\n",
        "\n",
        "# Preprocessing\n",
        "data.dropna(inplace=True)  # Remove any rows with missing values\n",
        "data = data[['Abstract', 'Summarized Abstract']]  # Select the relevant columns\n",
        "\n",
        "# Split data into training (75%) and test (25%)\n",
        "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
        "\n",
        "# Tokenization and padding for text data\n",
        "tokenizer = Tokenizer(num_words=5000)  # You can adjust the num_words parameter\n",
        "tokenizer.fit_on_texts(train_data['Abstract'])\n",
        "X_train = tokenizer.texts_to_sequences(train_data['Abstract'])\n",
        "X_test = tokenizer.texts_to_sequences(test_data['Abstract'])\n",
        "max_len = 100  # You can adjust this based on your data\n",
        "X_train = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')\n",
        "X_test = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')\n",
        "\n",
        "# Tokenize and pad the target data (Summarized Abstract)\n",
        "target_tokenizer = Tokenizer(num_words=5000)  # You can adjust the num_words parameter\n",
        "target_tokenizer.fit_on_texts(train_data['Summarized Abstract'])\n",
        "y_train = target_tokenizer.texts_to_sequences(train_data['Summarized Abstract'])\n",
        "y_test = target_tokenizer.texts_to_sequences(test_data['Summarized Abstract'])\n",
        "max_summary_len = 48  # You can adjust this based on your data\n",
        "\n",
        "# Padding or truncating the input sequences\n",
        "X_train = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')\n",
        "X_test = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')\n",
        "\n",
        "# Padding or truncating the target sequences\n",
        "y_train = pad_sequences(y_train, maxlen=max_summary_len, padding='post', truncating='post')\n",
        "y_test = pad_sequences(y_test, maxlen=max_summary_len, padding='post', truncating='post')\n",
        "\n",
        "# Build and compile the BiLSTM model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=5000, output_dim=100, input_length=max_len),\n",
        "    tf.keras.layers.Conv1D(128, 5, activation='relu'),  # You can adjust the filter size and number of filters\n",
        "    tf.keras.layers.MaxPooling1D(2),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, activation='relu', return_sequences=True)),\n",
        "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(5000, activation='softmax'))\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=16)\n",
        "\n",
        "# Generate predicted summaries for the test data\n",
        "predicted_summaries = model.predict(X_test)\n",
        "\n",
        "# Convert sequences back to text\n",
        "predicted_summaries_text = []\n",
        "for seq in predicted_summaries:\n",
        "    text_seq = [str(word) for word in seq]\n",
        "    text_seq = ' '.join(text_seq).strip()\n",
        "    predicted_summaries_text.append(text_seq)\n",
        "\n",
        "actual_summaries_text = []\n",
        "for seq in y_test:\n",
        "    text_seq = [str(word) for word in seq]\n",
        "    text_seq = ' '.join(text_seq).strip()\n",
        "    actual_summaries_text.append(text_seq)\n",
        "\n",
        "# Calculate ROUGE scores\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "# Calculate ROUGE scores\n",
        "rouge_1 = corpus_bleu([actual_summaries_text], [predicted_summaries_text], weights=(1, 0, 0, 0))\n",
        "rouge_2 = corpus_bleu([actual_summaries_text], [predicted_summaries_text], weights=(0, 1, 0, 0))\n",
        "rouge_l = corpus_bleu([actual_summaries_text], [predicted_summaries_text], weights=(0, 0, 1, 0))\n",
        "rouge_lsum = corpus_bleu([actual_summaries_text], [predicted_summaries_text], weights=(0.25, 0.25, 0.25, 0.25))\n",
        "\n",
        "print(\"ROUGE-1:\", rouge_1)\n",
        "print(\"ROUGE-2:\", rouge_2)\n",
        "print(\"ROUGE-L:\", rouge_l)\n",
        "print(\"ROUGE-Lsum:\", rouge_lsum)\n"
      ],
      "metadata": {
        "id": "ma1BoccUwm6B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e365ac9a-b830-4eff-f2ab-2386572eaae3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "3/3 [==============================] - 7s 734ms/step - loss: 8.5153 - accuracy: 0.0075\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 1s 433ms/step - loss: 8.4937 - accuracy: 0.0486\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 1s 451ms/step - loss: 8.3934 - accuracy: 0.0503\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 1s 436ms/step - loss: 8.3298 - accuracy: 0.0463\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 1s 451ms/step - loss: 8.1150 - accuracy: 0.0475\n",
            "1/1 [==============================] - 0s 438ms/step\n",
            "ROUGE-1: 0\n",
            "ROUGE-2: 0\n",
            "ROUGE-L: 0\n",
            "ROUGE-Lsum: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#bilstm - PRINTING ACTUAL AND PREDICTED SUMMARIES TEXT\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_excel('/content/drive/MyDrive/idp_dataset/pubmed_abstracts_clinicaltextrouge.xlsx')\n",
        "\n",
        "# Preprocessing\n",
        "data.dropna(inplace=True)  # Remove any rows with missing values\n",
        "data = data[['Abstract', 'Summarized Abstract']]  # Select the relevant columns\n",
        "\n",
        "# Split data into training (75%) and test (25%)\n",
        "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
        "\n",
        "# Tokenization and padding for text data\n",
        "tokenizer = Tokenizer(num_words=5000)  # You can adjust the num_words parameter\n",
        "tokenizer.fit_on_texts(train_data['Abstract'])\n",
        "X_train = tokenizer.texts_to_sequences(train_data['Abstract'])\n",
        "X_test = tokenizer.texts_to_sequences(test_data['Abstract'])\n",
        "max_len = 100  # You can adjust this based on your data\n",
        "X_train = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')\n",
        "X_test = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')\n",
        "\n",
        "# Tokenize and pad the target data (Summarized Abstract)\n",
        "target_tokenizer = Tokenizer(num_words=5000)  # You can adjust the num_words parameter\n",
        "target_tokenizer.fit_on_texts(train_data['Summarized Abstract'])\n",
        "y_train = target_tokenizer.texts_to_sequences(train_data['Summarized Abstract'])\n",
        "y_test = target_tokenizer.texts_to_sequences(test_data['Summarized Abstract'])\n",
        "max_summary_len = 48  # You can adjust this based on your data\n",
        "\n",
        "# Padding or truncating the input sequences\n",
        "X_train = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')\n",
        "X_test = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')\n",
        "\n",
        "# Padding or truncating the target sequences\n",
        "y_train = pad_sequences(y_train, maxlen=max_summary_len, padding='post', truncating='post')\n",
        "y_test = pad_sequences(y_test, maxlen=max_summary_len, padding='post', truncating='post')\n",
        "\n",
        "# Build and compile the BiLSTM model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=5000, output_dim=100, input_length=max_len),\n",
        "    tf.keras.layers.Conv1D(128, 5, activation='relu'),  # You can adjust the filter size and number of filters\n",
        "    tf.keras.layers.MaxPooling1D(2),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, activation='relu', return_sequences=True)),\n",
        "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(5000, activation='softmax'))\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=16)\n",
        "\n",
        "predicted_summaries = model.predict(X_test)\n",
        "\n",
        "# Implement beam search\n",
        "def beam_search_decoder(data, k):\n",
        "    sequences = [[list(), 1.0]]\n",
        "    for row in data:\n",
        "        all_candidates = list()\n",
        "        for i in range(len(sequences)):\n",
        "            seq, score = sequences[i]\n",
        "            for j in range(len(row)):\n",
        "                candidate = [seq + [j], score * -np.log(row[j])]\n",
        "                all_candidates.append(candidate)\n",
        "        ordered = sorted(all_candidates, key=lambda tup: tup[1])\n",
        "        sequences = ordered[:k]\n",
        "    return sequences\n",
        "\n",
        "# Perform beam search for each example in the test data\n",
        "beam_search_results = [beam_search_decoder(sample, k=3) for sample in predicted_summaries]\n",
        "\n",
        "# Convert sequences back to text and print examples\n",
        "for i in range(10):  # You can change the range to print more examples\n",
        "    actual_summary = \" \".join([target_tokenizer.index_word.get(word, \"\") for word in y_test[i] if word != 0])\n",
        "    predicted_summaries_text = []\n",
        "    for beam_result in beam_search_results[i]:\n",
        "        predicted_summary = \" \".join([target_tokenizer.index_word.get(word, \"\") for word in beam_result[0] if word != 0])\n",
        "        predicted_summaries_text.append(predicted_summary)\n",
        "    print(f\"Example - Actual Summary: {actual_summary}\")\n",
        "    print(f\"Example - Predicted Summaries: {predicted_summaries_text}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coNzU4ok5U2s",
        "outputId": "59947334-2d3b-47f3-ac8a-5b1f49c37c4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "3/3 [==============================] - 5s 442ms/step - loss: 8.5154 - accuracy: 0.0243\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 1s 434ms/step - loss: 8.4923 - accuracy: 0.0498\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 2s 538ms/step - loss: 8.3892 - accuracy: 0.0492\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 2s 709ms/step - loss: 8.3843 - accuracy: 0.0446\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 2s 716ms/step - loss: 8.0541 - accuracy: 0.0457\n",
            "1/1 [==============================] - 1s 751ms/step\n",
            "Example - Actual Summary: are the primary for the of and and models have in understanding these however the of a such as a should factors this scoping review aims to identify and the most factors as well as for of and\n",
            "Example - Predicted Summaries: ['the the the the the in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in of of of of of of of of of of of of', 'the the the the the the in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in of of of of of of of of of of of of', 'the the the the in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in of of of of of of of of of of of of']\n",
            "\n",
            "Example - Actual Summary: the of clinical is a before more natural language processing models that high accuracy for 1 experience a large of accuracy when to the of this study is to develop methods that clinical the with improved we found improved models only when with in samples improving the score\n",
            "Example - Predicted Summaries: ['the the the the the the in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in of of of of of of of of of of of', 'the the the the the the in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in of of of of of of of of of of', 'the the the the the in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in of of of of of of of of of of of']\n",
            "\n",
            "Example - Actual Summary: the prevention of for patients with is still a great in clinical practice there are studies that to search for strategies to the and life for these patients we aim to the efficacy between different reported treatments by meta analysis most of the studies were high quality with\n",
            "Example - Predicted Summaries: ['the the the the the the in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in of of of of of of of of of of of', 'the the the the the the in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in of of of of of of of of of of of of', 'the the the the the in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in of of of of of of of of of of of']\n",
            "\n",
            "Example - Actual Summary: large language models problems via text gpt 4 outperformed chatgpt in from free text reports on cancer it also had a lower rate of 1 7 7 4 9 the study included patients underwent cancer follow up between 2021 and\n",
            "Example - Predicted Summaries: ['the the the the in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in of of of of of of of of of of of of', 'the the the the the in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in of of of of of of of of of of of of', 'the the the the in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in of of of of of of of of of of of']\n",
            "\n",
            "Example - Actual Summary: is a natural found in recent studies have shown that effects against a of cancer types this review a comprehensive overview of the current research and new perspectives on effect it may facilitate the of novel for cancer treatment the need for further clinical and clinical studies to\n",
            "Example - Predicted Summaries: ['the the the the the the in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in of of of of of of of of of of of', 'the the the the the the in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in of of of of of of of of of of of of', 'the the the the the the the in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in of of of of of of of of of of of']\n",
            "\n",
            "Example - Actual Summary: natural language processing nlp can be used to free text in medical nlp was designed using lists based and decision tree learning it performed better on a more structured format than an unstructured one the study the design of an nlp based approach for evaluation of free text\n",
            "Example - Predicted Summaries: ['the the the the the the in in in in in in in in in in in in in in in in in in in in in in in in in in in in in of in of of of of of of of of of of of', 'the the the the the the in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in of of of of of of of of of of of', 'the the the the the in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in of in of of of of of of of of of of of']\n",
            "\n",
            "Example - Actual Summary: the main of this were the clinical and the evaluation of conditions including pain and function the of patients with should include a method of and the degree of the value of for was and findings the routine of or testing is not recommended\n",
            "Example - Predicted Summaries: ['the the the the the in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in of of of of of of of of of of of', 'the the the the the the in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in of of of of of of of of of of of', 'the the the the the in the in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in of of of of of of of of of of of']\n",
            "\n",
            "Example - Actual Summary: study compared in to control was with laser six and six control               23 in the study different and of were found to be significantly different for the different conditions\n",
            "Example - Predicted Summaries: ['the the the the the in in in in in in in in in in in in in in in in in in in in in in in in in in in in of in of of of of of of of of of of of of of', 'the the the the the in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in of of of of of of of of of of of of of', 'the the the the the the in in in in in in in in in in in in in in in in in in in in in in in in in in in of in of of of of of of of of of of of of of']\n",
            "\n",
            "Example - Actual Summary: use was as no use or use across 1 2 or 4 the incidence rate of use increased significantly with the study that may be an part of a specific of risk future studies should include measures of and to better the variability in back to online back\n",
            "Example - Predicted Summaries: ['the the the the in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in of of in of of of of of of of of of of', 'the the the the in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in of of of of of of of of of of of of of', 'the the the the in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in of in in of of of of of of of of of of']\n",
            "\n",
            "Example - Actual Summary: in fast for the               time in an improved understanding of is necessary as these may and risk associated with fast 1 were screened and full text articles were to determine whether they results were reported studies investigating of fast and features\n",
            "Example - Predicted Summaries: ['the the the the the in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in of of of of of of of of of of of of', 'the the the the the the in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in of of of of of of of of of of of of', 'the the the the in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in of of of of of of of of of of of of']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CNN** + LSTM"
      ],
      "metadata": {
        "id": "Hkd1qZNHxI7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_excel('/content/drive/MyDrive/idp_dataset/pubmed_abstracts_clinicaltextrouge.xlsx')\n",
        "\n",
        "# Preprocessing\n",
        "data.dropna(inplace=True)  # Remove any rows with missing values\n",
        "data = data[['Abstract', 'Summarized Abstract']]  # Select the relevant columns\n",
        "\n",
        "# Split data into training (75%) and test (25%)\n",
        "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
        "\n",
        "# Tokenization and padding for text data\n",
        "tokenizer = Tokenizer(num_words=5000)  # You can adjust the num_words parameter\n",
        "tokenizer.fit_on_texts(train_data['Abstract'])\n",
        "X_train = tokenizer.texts_to_sequences(train_data['Abstract'])\n",
        "X_test = tokenizer.texts_to_sequences(test_data['Abstract'])\n",
        "max_len = 100  # You can adjust this based on your data\n",
        "X_train = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')\n",
        "X_test = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')\n",
        "\n",
        "# Tokenize and pad the target data (Summarized Abstract)\n",
        "target_tokenizer = Tokenizer(num_words=5000)  # You can adjust the num_words parameter\n",
        "target_tokenizer.fit_on_texts(train_data['Summarized Abstract'])\n",
        "y_train = target_tokenizer.texts_to_sequences(train_data['Summarized Abstract'])\n",
        "y_test = target_tokenizer.texts_to_sequences(test_data['Summarized Abstract'])\n",
        "max_summary_len = 48  # You can adjust this based on your data\n",
        "\n",
        "# Padding or truncating the input sequences\n",
        "X_train = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')\n",
        "X_test = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')\n",
        "\n",
        "# Padding or truncating the target sequences\n",
        "y_train = pad_sequences(y_train, maxlen=max_summary_len, padding='post', truncating='post')\n",
        "y_test = pad_sequences(y_test, maxlen=max_summary_len, padding='post', truncating='post')\n",
        "\n",
        "# Build and compile the CNN + LSTM model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=5000, output_dim=100, input_length=max_len),\n",
        "    tf.keras.layers.Conv1D(128, 5, activation='relu'),  # You can adjust the filter size and number of filters\n",
        "    tf.keras.layers.MaxPooling1D(2),\n",
        "    tf.keras.layers.LSTM(256, activation='relu', return_sequences=True),\n",
        "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(5000, activation='softmax'))\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=16)\n",
        "\n",
        "# Generate predicted summaries for the test data\n",
        "predicted_summaries = model.predict(X_test)\n",
        "\n",
        "# Convert sequences back to text\n",
        "predicted_summaries_text = []\n",
        "for seq in predicted_summaries:\n",
        "    text_seq = [str(word) for word in seq]\n",
        "    text_seq = ' '.join(text_seq).strip()\n",
        "    predicted_summaries_text.append(text_seq)\n",
        "\n",
        "actual_summaries_text = []\n",
        "for seq in y_test:\n",
        "    text_seq = [str(word) for word in seq]\n",
        "    text_seq = ' '.join(text_seq).strip()\n",
        "    actual_summaries_text.append(text_seq)\n",
        "\n",
        "# Calculate ROUGE scores\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "# Calculate ROUGE scores\n",
        "rouge_1 = corpus_bleu([actual_summaries_text], [predicted_summaries_text], weights=(1, 0, 0, 0))\n",
        "rouge_2 = corpus_bleu([actual_summaries_text], [predicted_summaries_text], weights=(0, 1, 0, 0))\n",
        "rouge_l = corpus_bleu([actual_summaries_text], [predicted_summaries_text], weights=(0, 0, 1, 0))\n",
        "rouge_lsum = corpus_bleu([actual_summaries_text], [predicted_summaries_text], weights=(0.25, 0.25, 0.25, 0.25))\n",
        "\n",
        "print(\"ROUGE-1:\", rouge_1)\n",
        "print(\"ROUGE-2:\", rouge_2)\n",
        "print(\"ROUGE-L:\", rouge_l)\n",
        "print(\"ROUGE-Lsum:\", rouge_lsum)\n"
      ],
      "metadata": {
        "id": "4RhXKh2Iw8zA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "102d4e1b-3567-4edc-cb84-adebb0948a4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "3/3 [==============================] - 4s 326ms/step - loss: 8.5160 - accuracy: 0.0075\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 2s 549ms/step - loss: 8.5031 - accuracy: 0.0475\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 1s 497ms/step - loss: 8.4600 - accuracy: 0.0469\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 2s 573ms/step - loss: 8.6094 - accuracy: 0.0480\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 2s 712ms/step - loss: 8.1384 - accuracy: 0.0498\n",
            "1/1 [==============================] - 1s 505ms/step\n",
            "ROUGE-1: 0\n",
            "ROUGE-2: 0\n",
            "ROUGE-L: 0\n",
            "ROUGE-Lsum: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cnn+lstm PRINTING ACTUAL AND PREDICTED SUMMARIES\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_excel('/content/drive/MyDrive/idp_dataset/pubmed_abstracts_clinicaltextrouge.xlsx')\n",
        "\n",
        "# Preprocessing\n",
        "data.dropna(inplace=True)  # Remove any rows with missing values\n",
        "data = data[['Abstract', 'Summarized Abstract']]  # Select the relevant columns\n",
        "\n",
        "# Split data into training (75%) and test (25%)\n",
        "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
        "\n",
        "# Tokenization and padding for text data\n",
        "tokenizer = Tokenizer(num_words=5000)  # You can adjust the num_words parameter\n",
        "tokenizer.fit_on_texts(train_data['Abstract'])\n",
        "X_train = tokenizer.texts_to_sequences(train_data['Abstract'])\n",
        "X_test = tokenizer.texts_to_sequences(test_data['Abstract'])\n",
        "max_len = 100  # You can adjust this based on your data\n",
        "X_train = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')\n",
        "X_test = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')\n",
        "\n",
        "# Tokenize and pad the target data (Summarized Abstract)\n",
        "target_tokenizer = Tokenizer(num_words=5000)  # You can adjust the num_words parameter\n",
        "target_tokenizer.fit_on_texts(train_data['Summarized Abstract'])\n",
        "y_train = target_tokenizer.texts_to_sequences(train_data['Summarized Abstract'])\n",
        "y_test = target_tokenizer.texts_to_sequences(test_data['Summarized Abstract'])\n",
        "max_summary_len = 48  # You can adjust this based on your data\n",
        "\n",
        "# Padding or truncating the input sequences\n",
        "X_train = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')\n",
        "X_test = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')\n",
        "\n",
        "# Padding or truncating the target sequences\n",
        "y_train = pad_sequences(y_train, maxlen=max_summary_len, padding='post', truncating='post')\n",
        "y_test = pad_sequences(y_test, maxlen=max_summary_len, padding='post', truncating='post')\n",
        "\n",
        "# Build and compile the CNN + LSTM model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=5000, output_dim=100, input_length=max_len),\n",
        "    tf.keras.layers.Conv1D(128, 5, activation='relu'),  # You can adjust the filter size and number of filters\n",
        "    tf.keras.layers.MaxPooling1D(2),\n",
        "    tf.keras.layers.LSTM(256, activation='relu', return_sequences=True),\n",
        "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(5000, activation='softmax'))\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=16)\n",
        "\n",
        "# Generate predicted summaries for the test data\n",
        "predicted_summaries = model.predict(X_test)\n",
        "\n",
        "# Implement beam search\n",
        "def beam_search_decoder(data, k):\n",
        "    sequences = [[list(), 1.0]]\n",
        "    for row in data:\n",
        "        all_candidates = list()\n",
        "        for i in range(len(sequences)):\n",
        "            seq, score = sequences[i]\n",
        "            for j in range(len(row)):\n",
        "                candidate = [seq + [j], score * -np.log(row[j])]\n",
        "                all_candidates.append(candidate)\n",
        "        ordered = sorted(all_candidates, key=lambda tup: tup[1])\n",
        "        sequences = ordered[:k]\n",
        "    return sequences\n",
        "\n",
        "# Perform beam search for each example in the test data\n",
        "beam_search_results = [beam_search_decoder(sample, k=3) for sample in predicted_summaries]\n",
        "\n",
        "# Convert sequences back to text and print examples\n",
        "for i in range(10):  # You can change the range to print more examples\n",
        "    actual_summary = \" \".join([target_tokenizer.index_word.get(word, \"\") for word in y_test[i] if word != 0])\n",
        "    predicted_summaries_text = []\n",
        "    for beam_result in beam_search_results[i]:\n",
        "        predicted_summary = \" \".join([target_tokenizer.index_word.get(word, \"\") for word in beam_result[0] if word != 0])\n",
        "        predicted_summaries_text.append(predicted_summary)\n",
        "    print(f\"Example - Actual Summary: {actual_summary}\")\n",
        "    print(f\"Example - Predicted Summaries: {predicted_summaries_text}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7IRXMmc-kGZ",
        "outputId": "de29b3b7-339a-4872-e378-a5252e1259c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "3/3 [==============================] - 4s 436ms/step - loss: 8.5162 - accuracy: 5.7870e-04\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 1s 271ms/step - loss: 8.5025 - accuracy: 0.0376\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 1s 342ms/step - loss: 8.4499 - accuracy: 0.0330\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 1s 275ms/step - loss: 8.7406 - accuracy: 0.0347\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 1s 267ms/step - loss: 8.2744 - accuracy: 0.0480\n",
            "1/1 [==============================] - 0s 417ms/step\n",
            "Example - Actual Summary: are the primary for the of and and models have in understanding these however the of a such as a should factors this scoping review aims to identify and the most factors as well as for of and\n",
            "Example - Predicted Summaries: ['the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'in the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'of the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the']\n",
            "\n",
            "Example - Actual Summary: the of clinical is a before more natural language processing models that high accuracy for 1 experience a large of accuracy when to the of this study is to develop methods that clinical the with improved we found improved models only when with in samples improving the score\n",
            "Example - Predicted Summaries: ['the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'in the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the']\n",
            "\n",
            "Example - Actual Summary: the prevention of for patients with is still a great in clinical practice there are studies that to search for strategies to the and life for these patients we aim to the efficacy between different reported treatments by meta analysis most of the studies were high quality with\n",
            "Example - Predicted Summaries: ['the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'in the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the']\n",
            "\n",
            "Example - Actual Summary: large language models problems via text gpt 4 outperformed chatgpt in from free text reports on cancer it also had a lower rate of 1 7 7 4 9 the study included patients underwent cancer follow up between 2021 and\n",
            "Example - Predicted Summaries: ['the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'the the in the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'the the to the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the']\n",
            "\n",
            "Example - Actual Summary: is a natural found in recent studies have shown that effects against a of cancer types this review a comprehensive overview of the current research and new perspectives on effect it may facilitate the of novel for cancer treatment the need for further clinical and clinical studies to\n",
            "Example - Predicted Summaries: ['in the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'of the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the']\n",
            "\n",
            "Example - Actual Summary: natural language processing nlp can be used to free text in medical nlp was designed using lists based and decision tree learning it performed better on a more structured format than an unstructured one the study the design of an nlp based approach for evaluation of free text\n",
            "Example - Predicted Summaries: ['the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'in the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'to the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the']\n",
            "\n",
            "Example - Actual Summary: the main of this were the clinical and the evaluation of conditions including pain and function the of patients with should include a method of and the degree of the value of for was and findings the routine of or testing is not recommended\n",
            "Example - Predicted Summaries: ['the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'of the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the']\n",
            "\n",
            "Example - Actual Summary: study compared in to control was with laser six and six control               23 in the study different and of were found to be significantly different for the different conditions\n",
            "Example - Predicted Summaries: ['in the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'in to the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'in in the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the']\n",
            "\n",
            "Example - Actual Summary: use was as no use or use across 1 2 or 4 the incidence rate of use increased significantly with the study that may be an part of a specific of risk future studies should include measures of and to better the variability in back to online back\n",
            "Example - Predicted Summaries: ['in the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'in to the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the']\n",
            "\n",
            "Example - Actual Summary: in fast for the               time in an improved understanding of is necessary as these may and risk associated with fast 1 were screened and full text articles were to determine whether they results were reported studies investigating of fast and features\n",
            "Example - Predicted Summaries: ['the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'to the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the', 'in the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the']\n",
            "\n"
          ]
        }
      ]
    }
  ]
}